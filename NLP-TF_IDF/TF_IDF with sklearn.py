# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lMzsX__tNYl7cGYGuhgUh3r7oDO3QWaj

불용어 리스트
"""

conjunct=['그리고', '게다가', '더욱이', '더구나', '아울러', '뿐만', '뿐만 아니라', '어쩌면',
          '그러나', '하지만', '그렇지만', '그럼에도', '반면에', '도리어', '오히려', 
          '그러므로', '따라서', '그러니까', '그리하여', '그렇게', '때문에', '그래서',
          '그러면', '그러니', '마침내', '왜냐하면', '그런데', '즉', '말하자면', '사실상',
          '예컨데', '끝으로', '결국', '결론적으로', '마지막으로', '정말', '너무', '엄청', '많이', '싶은']
post=['이', '가', '이다', '을', '를', '의', '에', '에서', '로', '와', '과', '보다', '아', '야', 
      '랑', '며', '이랑', '이며', '나', '은', '는', '만', '밖에', '뿐', '도', '조차', '마저',
      '까지', '이나', '든지', '이든지', '나마', '이나마', '라도', '이라도']

pip install nltk

import nltk
nltk.download('punkt')

"""불용어 제거 자체 알고리즘 테스트"""

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
test='그런데 저는 과일이 너무 좋습니다. 하지만 나는 야채는 정말 싫어합니다.'
test=test.replace(".", "")
tokens=word_tokenize(test)
process=[]
for t in tokens:
  if t in conjunct:
    continue
  else:
    if t[len(t)-1] in post:
      t=t.rstrip(t[len(t)-1])
      process.append(t)
    else:
      process.append(t)
aftertest=" ".join(process)
print(aftertest)

"""konlpy 활용 조사/접속사 제거 알고리즘"""

pip install konlpy

import konlpy.tag
docs = [
  '그런데 먹고 싶은 사과',
  '먹고 싶은 바나나',
  '길고 노란 바나나 바나나',
  '저는 과일이 좋아요',
  '먹고 싶은 사과',
  '사과는 영어로 apple 입니다'
] 
after_docs=[]
for now in docs:
  Okt=konlpy.tag.Okt()
  Okt_morphs=Okt.pos(now)
  temp=[]
  for word, pos in Okt_morphs:
    if pos=="Josa" or pos=="Conjunction":
      continue
    else:
      temp.append(word)
  newsent=" ".join(temp)
  after_docs.append(newsent)
print(after_docs)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

"""DTM 생성"""

vector=CountVectorizer()
dtm=vector.fit_transform(after_docs).toarray()
print(dtm)
print(vector.vocabulary_)

"""TF-IDF 생성"""

tfidfv=TfidfVectorizer().fit(after_docs)
tfidf=tfidfv.transform(after_docs).toarray()
print(tfidf)
print(tfidfv.vocabulary_)

"""코사인 유사도"""

from numpy import dot
from numpy.linalg import norm
import numpy as np
def cos_sim(A, B):
       return dot(A, B)/(norm(A)*norm(B))

print(cos_sim(tfidf[0], tfidf[1]))
print(cos_sim(tfidf[0], tfidf[2]))
print(cos_sim(tfidf[1], tfidf[2]))
print(cos_sim(tfidf[0], tfidf[4]))

from sklearn.metrics.pairwise import linear_kernel
cosine_sim=linear_kernel(tfidf, tfidf)
print(cosine_sim)